{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9030d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5393035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TensorFlow tutorials are written as Jupyter notebooks and run directly in Google Colabâ€”a hosted notebook environment that requires no setup. At the top of each tutorial, you'll see a Run in Google Colab button. Click the button to open the notebook and run the code yourself.\n",
      "\n",
      "For beginners\n",
      "The best place to start is with the user-friendly Keras sequential API. Build models by plugging together building blocks. After these tutorials, read the Keras guide.\n",
      "Beginner quickstart\n",
      "This \"Hello, World!\" notebook shows the Keras Sequential API and model.fit.\n",
      "Keras basics\n",
      "This notebook collection demonstrates basic machine learning tasks using Keras.\n",
      "Load data\n",
      "These tutorials use tf.data to load various data formats and build input pipelines.\n",
      "For experts\n",
      "The Keras functional and subclassing APIs provide a define-by-run interface for customization and advanced research. Build your model, then write the forward and backward pass. Create custom layers, activations, and training loops.\n",
      "Advanced quickstart\n",
      "This \"Hello, World!\" notebook uses the Keras subclassing API and a custom training loop.\n",
      "Customization\n",
      "This notebook collection shows how to build custom layers and training loops in TensorFlow.\n",
      "Distributed training\n",
      "Distribute your model training across multiple GPUs, multiple machines or TPUs.\n",
      "The Advanced section has many instructive notebooks examples, including Neural machine translation, Transformers, and CycleGAN.\n"
     ]
    }
   ],
   "source": [
    "with open('input_txt.txt', 'r') as input:\n",
    "    input_content = input.read()\n",
    "    \n",
    "print(input_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db6a5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247 ['The', 'TensorFlow', 'tutorials', 'are', 'written', 'as', 'Jupyter', 'notebooks', 'and', 'run', 'directly', 'in', 'Google', 'Colabâ€”a', 'hosted', 'notebook', 'environment', 'that', 'requires', 'no', 'setup', '.', 'At', 'the', 'top', 'of', 'each', 'tutorial', ',', 'you', \"'\", 'll', 'see', 'a', 'Run', 'in', 'Google', 'Colab', 'button', '.', 'Click', 'the', 'button', 'to', 'open', 'the', 'notebook', 'and', 'run', 'the', 'code', 'yourself', '.', 'For', 'beginners', 'The', 'best', 'place', 'to', 'start', 'is', 'with', 'the', 'user-friendly', 'Keras', 'sequential', 'API', '.', 'Build', 'models', 'by', 'plugging', 'together', 'building', 'blocks', '.', 'After', 'these', 'tutorials', ',', 'read', 'the', 'Keras', 'guide', '.', 'Beginner', 'quickstart', 'This', '\"', 'Hello', ',', 'World', '!', '\"', 'notebook', 'shows', 'the', 'Keras', 'Sequential', 'API', 'and', 'model', '.', 'fit', '.', 'Keras', 'basics', 'This', 'notebook', 'collection', 'demonstrates', 'basic', 'machine', 'learning', 'tasks', 'using', 'Keras', '.', 'Load', 'data', 'These', 'tutorials', 'use', 'tf', '.', 'data', 'to', 'load', 'various', 'data', 'formats', 'and', 'build', 'input', 'pipelines', '.', 'For', 'experts', 'The', 'Keras', 'functional', 'and', 'subclassing', 'APIs', 'provide', 'a', 'define-by-run', 'interface', 'for', 'customization', 'and', 'advanced', 'research', '.', 'Build', 'your', 'model', ',', 'then', 'write', 'the', 'forward', 'and', 'backward', 'pass', '.', 'Create', 'custom', 'layers', ',', 'activations', ',', 'and', 'training', 'loops', '.', 'Advanced', 'quickstart', 'This', '\"', 'Hello', ',', 'World', '!', '\"', 'notebook', 'uses', 'the', 'Keras', 'subclassing', 'API', 'and', 'a', 'custom', 'training', 'loop', '.', 'Customization', 'This', 'notebook', 'collection', 'shows', 'how', 'to', 'build', 'custom', 'layers', 'and', 'training', 'loops', 'in', 'TensorFlow', '.', 'Distributed', 'training', 'Distribute', 'your', 'model', 'training', 'across', 'multiple', 'GPUs', ',', 'multiple', 'machines', 'or', 'TPUs', '.', 'The', 'Advanced', 'section', 'has', 'many', 'instructive', 'notebooks', 'examples', ',', 'including', 'Neural', 'machine', 'translation', ',', 'Transformers', ',', 'and', 'CycleGAN', '.']\n"
     ]
    }
   ],
   "source": [
    "# create tokens\n",
    "tokens = re.split(r'([,.:;?_!\"()\\']|--|\\s)', input_content)\n",
    "# removing all leading and trailing white spaces\n",
    "tokens = [item.strip() for item in tokens if item.strip()]\n",
    "\n",
    "print(len(tokens), tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dff1c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 ['!', '\"', \"'\", ',', '.', 'API', 'APIs', 'Advanced', 'After', 'At', 'Beginner', 'Build', 'Click', 'Colab', 'Colabâ€”a', 'Create', 'Customization', 'CycleGAN', 'Distribute', 'Distributed', 'For', 'GPUs', 'Google', 'Hello', 'Jupyter', 'Keras', 'Load', 'Neural', 'Run', 'Sequential', 'TPUs', 'TensorFlow', 'The', 'These', 'This', 'Transformers', 'World', 'a', 'across', 'activations', 'advanced', 'and', 'are', 'as', 'backward', 'basic', 'basics', 'beginners', 'best', 'blocks', 'build', 'building', 'button', 'by', 'code', 'collection', 'custom', 'customization', 'data', 'define-by-run', 'demonstrates', 'directly', 'each', 'environment', 'examples', 'experts', 'fit', 'for', 'formats', 'forward', 'functional', 'guide', 'has', 'hosted', 'how', 'in', 'including', 'input', 'instructive', 'interface', 'is', 'layers', 'learning', 'll', 'load', 'loop', 'loops', 'machine', 'machines', 'many', 'model', 'models', 'multiple', 'no', 'notebook', 'notebooks', 'of', 'open', 'or', 'pass', 'pipelines', 'place', 'plugging', 'provide', 'quickstart', 'read', 'requires', 'research', 'run', 'section', 'see', 'sequential', 'setup', 'shows', 'start', 'subclassing', 'tasks', 'tf', 'that', 'the', 'then', 'these', 'to', 'together', 'top', 'training', 'translation', 'tutorial', 'tutorials', 'use', 'user-friendly', 'uses', 'using', 'various', 'with', 'write', 'written', 'you', 'your', 'yourself']\n",
      "140 {'!': 0, '\"': 1, \"'\": 2, ',': 3, '.': 4, 'API': 5, 'APIs': 6, 'Advanced': 7, 'After': 8, 'At': 9, 'Beginner': 10, 'Build': 11, 'Click': 12, 'Colab': 13, 'Colabâ€”a': 14, 'Create': 15, 'Customization': 16, 'CycleGAN': 17, 'Distribute': 18, 'Distributed': 19, 'For': 20, 'GPUs': 21, 'Google': 22, 'Hello': 23, 'Jupyter': 24, 'Keras': 25, 'Load': 26, 'Neural': 27, 'Run': 28, 'Sequential': 29, 'TPUs': 30, 'TensorFlow': 31, 'The': 32, 'These': 33, 'This': 34, 'Transformers': 35, 'World': 36, 'a': 37, 'across': 38, 'activations': 39, 'advanced': 40, 'and': 41, 'are': 42, 'as': 43, 'backward': 44, 'basic': 45, 'basics': 46, 'beginners': 47, 'best': 48, 'blocks': 49, 'build': 50, 'building': 51, 'button': 52, 'by': 53, 'code': 54, 'collection': 55, 'custom': 56, 'customization': 57, 'data': 58, 'define-by-run': 59, 'demonstrates': 60, 'directly': 61, 'each': 62, 'environment': 63, 'examples': 64, 'experts': 65, 'fit': 66, 'for': 67, 'formats': 68, 'forward': 69, 'functional': 70, 'guide': 71, 'has': 72, 'hosted': 73, 'how': 74, 'in': 75, 'including': 76, 'input': 77, 'instructive': 78, 'interface': 79, 'is': 80, 'layers': 81, 'learning': 82, 'll': 83, 'load': 84, 'loop': 85, 'loops': 86, 'machine': 87, 'machines': 88, 'many': 89, 'model': 90, 'models': 91, 'multiple': 92, 'no': 93, 'notebook': 94, 'notebooks': 95, 'of': 96, 'open': 97, 'or': 98, 'pass': 99, 'pipelines': 100, 'place': 101, 'plugging': 102, 'provide': 103, 'quickstart': 104, 'read': 105, 'requires': 106, 'research': 107, 'run': 108, 'section': 109, 'see': 110, 'sequential': 111, 'setup': 112, 'shows': 113, 'start': 114, 'subclassing': 115, 'tasks': 116, 'tf': 117, 'that': 118, 'the': 119, 'then': 120, 'these': 121, 'to': 122, 'together': 123, 'top': 124, 'training': 125, 'translation': 126, 'tutorial': 127, 'tutorials': 128, 'use': 129, 'user-friendly': 130, 'uses': 131, 'using': 132, 'various': 133, 'with': 134, 'write': 135, 'written': 136, 'you': 137, 'your': 138, 'yourself': 139}\n"
     ]
    }
   ],
   "source": [
    "# creating token IDs\n",
    "\n",
    "# 1. sort the tokens in alphabetical order without duplicates\n",
    "tokens = sorted(set(tokens))\n",
    "print(len(tokens), tokens)\n",
    "\n",
    "# 2. add IDs to tokens\n",
    "vocab = {token:id for id, token in enumerate(tokens)}\n",
    "print(len(vocab), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfb6ced1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', \"'\", ',', '.', 'API', 'APIs', 'Advanced', 'After', 'At', 'Beginner', 'Build', 'Click', 'Colab', 'Colabâ€”a', 'Create', 'Customization', 'CycleGAN', 'Distribute', 'Distributed', 'For', 'GPUs', 'Google', 'Hello', 'Jupyter', 'Keras', 'Load', 'Neural', 'Run', 'Sequential', 'TPUs', 'TensorFlow', 'The', 'These', 'This', 'Transformers', 'World', 'a', 'across', 'activations', 'advanced', 'and', 'are', 'as', 'backward', 'basic', 'basics', 'beginners', 'best', 'blocks', 'build', 'building', 'button', 'by', 'code', 'collection', 'custom', 'customization', 'data', 'define-by-run', 'demonstrates', 'directly', 'each', 'environment', 'examples', 'experts', 'fit', 'for', 'formats', 'forward', 'functional', 'guide', 'has', 'hosted', 'how', 'in', 'including', 'input', 'instructive', 'interface', 'is', 'layers', 'learning', 'll', 'load', 'loop', 'loops', 'machine', 'machines', 'many', 'model', 'models', 'multiple', 'no', 'notebook', 'notebooks', 'of', 'open', 'or', 'pass', 'pipelines', 'place', 'plugging', 'provide', 'quickstart', 'read', 'requires', 'research', 'run', 'section', 'see', 'sequential', 'setup', 'shows', 'start', 'subclassing', 'tasks', 'tf', 'that', 'the', 'then', 'these', 'to', 'together', 'top', 'training', 'translation', 'tutorial', 'tutorials', 'use', 'user-friendly', 'uses', 'using', 'various', 'with', 'write', 'written', 'you', 'your', 'yourself', '<|endoftext|>', '<|unknown|>', '<|endoftext|>', '<|unknown|>', '<|endoftext|>', '<|unknown|>', '<|endoftext|>', '<|unknown|>', '<|endoftext|>', '<|unknown|>', '<|endoftext|>', '<|unknown|>']\n",
      "('you', 137)\n",
      "('your', 138)\n",
      "('yourself', 139)\n",
      "('<|endoftext|>', 150)\n",
      "('<|unknown|>', 151)\n"
     ]
    }
   ],
   "source": [
    "# # We can modify the tokenizer to use an <|unk|> token if it\n",
    "# # encounters a word that is not part of the vocabulary. \n",
    "\n",
    "# # Furthermore, we add a token between\n",
    "# # unrelated texts. \n",
    "\n",
    "# # For example, when training GPT-like LLMs on multiple independent\n",
    "# # documents or books, it is common to insert a token before each document or book that\n",
    "# # follows a previous text source\n",
    "\n",
    "# Let's now modify the vocabulary to include these two special tokens, <unk> and\n",
    "# <|endoftext|>, by adding these to the list of all unique words that we created in the\n",
    "# previous section:\n",
    "\n",
    "tokens.extend(['<|endoftext|>', '<|unknown|>'])\n",
    "print(tokens)\n",
    "\n",
    "all_vocab = {token:id for id, token in enumerate(tokens)}\n",
    "\n",
    "\n",
    "for i, item in enumerate(list(all_vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50d9353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unknown|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(all_vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    " \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "899c8daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 3, 151, 137, 151, 151, 151, 150, 151, 119, 151, 151, 96, 119, 151, 4]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86b6ccbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, <|unknown|> you <|unknown|> <|unknown|> <|unknown|> <|endoftext|> <|unknown|> the <|unknown|> <|unknown|> of the <|unknown|>.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "462bd6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The TensorFlow tutorials are written as Jupyter notebooks and run directly in Google Colabâ€”a hosted notebook environment that requires no setup. At the top of each tutorial, you\\' ll see a Run in Google Colab button. Click the button to open the notebook and run the code yourself. For beginners The best place to start is with the user-friendly Keras sequential API. Build models by plugging together building blocks. After these tutorials, read the Keras guide. Beginner quickstart This\" Hello, World!\" notebook shows the Keras Sequential API and model. fit. Keras basics This notebook collection demonstrates basic machine learning tasks using Keras. Load data These tutorials use tf. data to load various data formats and build input pipelines. For experts The Keras functional and subclassing APIs provide a define-by-run interface for customization and advanced research. Build your model, then write the forward and backward pass. Create custom layers, activations, and training loops. Advanced quickstart This\" Hello, World!\" notebook uses the Keras subclassing API and a custom training loop. Customization This notebook collection shows how to build custom layers and training loops in TensorFlow. Distributed training Distribute your model training across multiple GPUs, multiple machines or TPUs. The Advanced section has many instructive notebooks examples, including Neural machine translation, Transformers, and CycleGAN.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(input_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea344da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
